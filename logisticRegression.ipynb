{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age\n",
       "0         0       3    2  22.0\n",
       "1         1       1    1  38.0\n",
       "2         1       3    1  26.0\n",
       "3         1       1    1  35.0\n",
       "4         0       3    2  35.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the file\n",
    "df = pd.read_csv('data/titanicdata.csv', header=0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data using the formula (x - min(x)) / (max(x) - min(x))\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex       Age\n",
       "0       0.0     1.0  1.0  0.271174\n",
       "1       1.0     0.0  0.0  0.472229\n",
       "2       1.0     1.0  0.0  0.321438\n",
       "3       1.0     0.0  0.0  0.434531\n",
       "4       0.0     1.0  1.0  0.434531"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standardized = normalize(df)\n",
    "df_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to numpy array\n",
    "df_standardized_array = df_standardized.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iter=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "        \n",
    "        \n",
    "        # Iterate over the number of maximum iterations\n",
    "        for _ in range(self.max_iter):\n",
    "            # Compute the dot product of the input features and the weights\n",
    "            z = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # for numeric stability\n",
    "            #z -= np.max(z)\n",
    "\n",
    "            # Compute the conditional log-likelihood of the data\n",
    "            log_likelihood = np.sum(y * (z)) - np.sum(np.log(1 + np.exp(z)))\n",
    "\n",
    "            # compute loss\n",
    "            loss = -np.sum(y * np.log(sigmoid(z)) + (1 - y) * np.log(1 - sigmoid(z)))\n",
    "\n",
    "            # print loss\n",
    "            #print(\"loss is\", loss)\n",
    "            \n",
    "            # Compute the gradient of the weights and bias\n",
    "            gradient_bias    = np.sum(y - ((np.exp(z)) / (1 + np.exp(z))))\n",
    "            gradient_weights = ((X.T * (y - ( (np.exp(z)) / (1 + np.exp(z)) ) )).T).sum(axis=0)\n",
    "       \n",
    "            # Update the weights and bias\n",
    "            self.weights += self.learning_rate * gradient_weights\n",
    "            self.bias += self.learning_rate * gradient_bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Compute the dot product of the input features and the weights\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        \n",
    "        # Apply the sigmoid function to the dot product to get the predictions\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # Return the predictions as a class label (0 or 1)\n",
    "        return np.round(y_pred).astype(int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into three random sets, 60% as train, 20% validation and 20% as test\n",
    "train, validate, test = np.split(df_standardized_array, [int(.6*len(df_standardized_array)), int(.8*len(df_standardized_array))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first feature is the label\n",
    "train_X, train_y = train[:, 1:], train[:, 0]\n",
    "validate_X, validate_y = validate[:, 1:], validate[:, 0]\n",
    "test_X, test_y = test[:, 1:], test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 8371.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 370.14059441901077\n",
      "loss is 351.5877922304335\n",
      "loss is 340.51969689325733\n",
      "loss is 333.37775603299906\n",
      "loss is 328.33642101621876\n",
      "loss is 324.4581046433018\n",
      "loss is 321.2528215167764\n",
      "loss is 318.45876881837285\n",
      "loss is 315.93279451420983\n",
      "loss is 313.59473685182337\n",
      "loss is 311.39851744877626\n",
      "loss is 309.3168111087536\n",
      "loss is 307.33276462639225\n",
      "loss is 305.4354533724686\n",
      "loss is 303.6173564443444\n",
      "loss is 301.8729387628625\n",
      "loss is 300.1978478720862\n",
      "loss is 298.58845556866106\n",
      "loss is 297.041594536164\n",
      "loss is 295.55440595608667\n",
      "loss is 294.124250582497\n",
      "loss is 292.74865624084487\n",
      "loss is 291.4252862858493\n",
      "loss is 290.1519201405564\n",
      "loss is 288.92644080729065\n",
      "loss is 287.74682640615083\n",
      "loss is 286.61114404416287\n",
      "loss is 285.517545038475\n",
      "loss is 284.46426093329643\n",
      "loss is 283.4495999908884\n",
      "loss is 282.47194397577186\n",
      "loss is 281.5297451311914\n",
      "loss is 280.6215232925557\n",
      "loss is 279.7458631084575\n",
      "loss is 278.9014113543209\n",
      "loss is 278.0868743315873\n",
      "loss is 277.3010153494655\n",
      "loss is 276.5426522882643\n",
      "loss is 275.8106552441459\n",
      "loss is 275.1039442553344\n",
      "loss is 274.421487109686\n",
      "loss is 273.76229723326014\n",
      "loss is 273.1254316592091\n",
      "loss is 272.5099890759915\n",
      "loss is 271.9151079536226\n",
      "loss is 271.339964746427\n",
      "loss is 270.7837721705449\n",
      "loss is 270.2457775542808\n",
      "loss is 269.72526125924196\n",
      "loss is 269.2215351701252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = LogisticRegression(learning_rate=0.001, max_iter=50)\n",
    "model.fit(train_X, train_y)\n",
    "# get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799625468164794"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train accuracy\n",
    "train_pred = model.predict(train_X)\n",
    "train_accuracy = np.sum(train_pred == train_y) / len(train_y)\n",
    "train_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is 0.0001 max iter is 10 validation accuracy is 0.601123595505618\n",
      "learning rate is 0.0001 max iter is 50 validation accuracy is 0.601123595505618\n",
      "learning rate is 0.0001 max iter is 100 validation accuracy is 0.601123595505618\n",
      "learning rate is 0.0001 max iter is 1000 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.001 max iter is 10 validation accuracy is 0.601123595505618\n",
      "learning rate is 0.001 max iter is 50 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.001 max iter is 100 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.001 max iter is 1000 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.01 max iter is 10 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.01 max iter is 50 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.01 max iter is 100 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.01 max iter is 1000 validation accuracy is 0.7359550561797753\n",
      "learning rate is 0.1 max iter is 10 validation accuracy is 0.398876404494382\n",
      "learning rate is 0.1 max iter is 50 validation accuracy is 0.7528089887640449\n",
      "learning rate is 0.1 max iter is 100 validation accuracy is 0.601123595505618\n",
      "learning rate is 0.1 max iter is 1000 validation accuracy is 0.7696629213483146\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "max_iters = [10, 50, 100, 1000]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for max_iter in max_iters:\n",
    "        model = LogisticRegression(learning_rate=learning_rate, max_iter=max_iter)\n",
    "        model.fit(train_X, train_y)\n",
    "        validate_pred = model.predict(validate_X)\n",
    "        validate_accuracy = np.sum(validate_pred == validate_y) / len(validate_y)\n",
    "        print(\"learning rate is\", learning_rate, \"max iter is\", max_iter, \"validation accuracy is\", validate_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine train and validation data\n",
    "train_valid_X = np.concatenate((train_X, validate_X), axis=0)\n",
    "train_valid_y = np.concatenate((train_y, validate_y), axis=0)\n",
    "\n",
    "# train the model with train and validation data\n",
    "model = LogisticRegression(learning_rate=0.001, max_iter=1000)\n",
    "model.fit(train_valid_X, train_valid_y)\n",
    "\n",
    "# predict on test data\n",
    "test_pred = model.predict(test_X)\n",
    "test_accuracy = np.sum(test_pred == test_y) / len(test_y)\n",
    "test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "754e1a82b9296535340b73459eda352880fb6a9e6d8b17e44d85dd0cb4a53b5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
